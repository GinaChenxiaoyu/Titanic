{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\\\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Title</th>\n",
       "      <th>Familysize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex  Age  Fare  Title  Familysize\n",
       "0       3    0  1.0   0.0      0           1\n",
       "1       1    1  1.0   1.0      1           1\n",
       "2       3    1  1.0   0.0      2           0\n",
       "3       1    1  1.0   1.0      1           1\n",
       "4       3    0  1.0   0.0      0           0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\train.csv\")\n",
    "df['Title'] = df['Name'].map(lambda x: re.compile(\",(.*?)\\.\").findall(x)[0])\n",
    "df['Title'] = df['Title'].map(str.strip) # 匹配的逗号后面有空格，记得去除空格，不然下一步没法替换\n",
    "df['Title'][df.Title=='Jonkheer'] = 'Master'  #master意为大师\n",
    "df['Title'][df.Title.isin(['Ms','Mlle'])] = 'Miss'   #多个带判断值时，用isin 比 == 好用。\n",
    "df['Title'][df.Title.isin(['Mme','Dona', 'Lady', 'the Countess'])] = 'Mrs'\n",
    "df['Title'][df.Title.isin(['Capt', 'Don', 'Major', 'Col', 'Sir'])] = 'Mr'\n",
    "df['Title'][df.Title.isin(['Dr','Rev'])] = 'DrAndRev'\n",
    "df['Title'] = pd.factorize(df.Title)[0]\n",
    "df['Sex'] = pd.factorize(df.Sex)[0]\n",
    "df['Familysize'] = df['SibSp'] + df[\"Parch\"]\n",
    "df['Familysize'][df.Familysize==0] = 0\n",
    "df['Familysize'][df.Familysize>0] = 1 # 分两类吧，带了亲戚，没带亲戚\n",
    "#import pylab as pl\n",
    "##在开头添加pylab的内嵌语句，pylab是 Matplotlib 和Ipython提供的一个模块，提供了类似Matlab的语法。\n",
    "#%pylab inline\n",
    "#pl.scatter(df.index,df['Age'])\n",
    "#pl.scatter(df.index,df['Fare'])\n",
    "df['Fare'][df.Fare<20] = 0\n",
    "df['Fare'][df.Fare>=20] = 1\n",
    "df_tag = df.Survived\n",
    "df_tag.to_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\train_tag.csv',  index=None)\n",
    "df.drop(['PassengerId', 'Name', 'SibSp' ,'Parch','Ticket', 'Cabin','Embarked'],inplace=True, axis=1)\n",
    "df['Age'][(df.Age<18)&(df.Age.notnull())] = 0\n",
    "df['Age'][(df.Age>=18)&(df.Age.notnull())] = 1\n",
    "#这块是处理Age的缺失值。\n",
    "y_train = df['Age'][df.Age.notnull()].values\n",
    "x_train = df[df.Age.notnull()].drop(['Age'],axis=1).values\n",
    "x_test = df[df.Age.isnull()].drop(['Age'],axis=1).values\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier().fit(x_train,y_train)\n",
    "df['Age'][df.Age.isnull()] = rfc.predict(x_test)\n",
    "df.drop(['Survived'],axis=1,inplace=True)\n",
    "df.to_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_train_feature.csv', header=None, index=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART TWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Title</th>\n",
       "      <th>Familysize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex  Age  Fare  Title  Familysize\n",
       "0       3    0  1.0   0.0      0           0\n",
       "1       3    1  1.0   0.0      1           1\n",
       "2       2    0  1.0   0.0      0           0\n",
       "3       3    0  1.0   0.0      0           0\n",
       "4       3    1  1.0   0.0      1           1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\test.csv\")\n",
    "df['Title'] = df['Name'].map(lambda x: re.compile(\",(.*?)\\.\").findall(x)[0])\n",
    "df['Title'] = df['Title'].map(str.strip)\n",
    "df['Title'][df.Title=='Jonkheer'] = 'Master'  #master意为大师\n",
    "df['Title'][df.Title.isin(['Ms','Mlle'])] = 'Miss'   #多个带判断值时，用isin 比 == 好用。\n",
    "df['Title'][df.Title.isin(['Mme','Dona', 'Lady', 'the Countess'])] = 'Mrs'\n",
    "df['Title'][df.Title.isin(['Capt', 'Don', 'Major', 'Col', 'Sir'])] = 'Mr'\n",
    "df['Title'][df.Title.isin(['Dr','Rev'])] = 'DrAndRev'\n",
    "df['Title'] = pd.factorize(df.Title)[0]\n",
    "df['Sex'] = pd.factorize(df.Sex)[0]\n",
    "df['Familysize'] = df['SibSp'] + df[\"Parch\"]\n",
    "df['Familysize'][df.Familysize==0] = 0\n",
    "df['Familysize'][df.Familysize>0] = 1\n",
    "df['Fare'][df.Fare<20] = 0\n",
    "df['Fare'][df.Fare>=20] = 1\n",
    "df.drop(['PassengerId', 'Name', 'SibSp' ,'Parch','Ticket', 'Cabin','Embarked'],inplace=True, axis=1)\n",
    "df['Age'][(df.Age<18)&(df.Age.notnull())] = 0\n",
    "df['Age'][(df.Age>=18)&(df.Age.notnull())] = 1\n",
    "df['Fare'][df.Fare.isnull()] = 10# 注意test的fare有个空值，我手改了\n",
    "y_train = df['Age'][df.Age.notnull()].values\n",
    "x_train = df[df.Age.notnull()].drop(['Age'],axis=1).values\n",
    "x_test = df[df.Age.isnull()].drop(['Age'],axis=1).values\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier().fit(x_train,y_train)\n",
    "df['Age'][df.Age.isnull()] = rfc.predict(x_test)\n",
    "df.to_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_test_feature.csv', header=None, index=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PART THREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def sub():\n",
    "    x_train = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_train_feature.csv', header=None).values\n",
    "    y_train = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\train_tag.csv', header=None).values\n",
    "    x_test = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_test_feature.csv', header=None).values\n",
    "    #集合方法\n",
    "    clf1 = svm.SVC(probability=True,random_state=7)\n",
    "    clf2 = RandomForestClassifier(random_state=7)\n",
    "    clf3 = GradientBoostingClassifier(random_state=7)\n",
    "    voting_class = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('dt', clf3)], voting='soft',\n",
    "                                    weights=[1, 1, 1])\n",
    "    vote = voting_class.fit(x_train, y_train)\n",
    "    #保存模型\n",
    "    joblib.dump(vote,r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\vote_sub7.model')\n",
    "    #vote = joblib.load(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\0.7835820895522388vote1.model')\n",
    "    y_test_pred = vote.predict(x_test)\n",
    "    pre = pd.DataFrame(y_test_pred,index=None,columns=['Survived'])\n",
    "    pre.to_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\pre7.csv\",index=None)\n",
    "    df = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\test.csv')\n",
    "    dfID = df.PassengerId\n",
    "    sub = pd.concat([dfID,pre],axis=1)\n",
    "    sub.to_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\sub7.csv\", index=None)\n",
    "    print (\"ok\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def sub():\n",
    "    x_train = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_train_feature.csv', header=None).values\n",
    "    y_train = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\train_tag.csv', header=None).values\n",
    "    x_test = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_test_feature.csv', header=None).values\n",
    "    #集合方法\n",
    "    clf1 = svm.SVC(probability=True,random_state=6)\n",
    "    clf2 = RandomForestClassifier(random_state=6)\n",
    "    clf3 = GradientBoostingClassifier(random_state=6)\n",
    "    voting_class = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('dt', clf3)], voting='soft',\n",
    "                                    weights=[1, 1, 1])\n",
    "    vote = voting_class.fit(x_train, y_train)\n",
    "    #保存模型\n",
    "    joblib.dump(vote,r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\vote_sub6.model')\n",
    "    #vote = joblib.load(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\0.7835820895522388vote1.model')\n",
    "    y_test_pred = vote.predict(x_test)\n",
    "    pre = pd.DataFrame(y_test_pred,index=None,columns=['Survived'])\n",
    "    pre.to_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\pre6.csv\",index=None)\n",
    "    df = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\test.csv')\n",
    "    dfID = df.PassengerId\n",
    "    sub = pd.concat([dfID,pre],axis=1)\n",
    "    sub.to_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\sub6.csv\", index=None)\n",
    "    print (\"ok\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def sub():\n",
    "    x_train = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_train_feature.csv', header=None).values\n",
    "    y_train = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\train_tag.csv', header=None).values\n",
    "    x_test = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_test_feature.csv', header=None).values\n",
    "    #集合方法\n",
    "    clf1 = svm.SVC(probability=True,random_state=5)\n",
    "    clf2 = RandomForestClassifier(random_state=5)\n",
    "    clf3 = GradientBoostingClassifier(random_state=5)\n",
    "    voting_class = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('dt', clf3)], voting='soft',\n",
    "                                    weights=[1, 1, 1])\n",
    "    vote = voting_class.fit(x_train, y_train)\n",
    "    #保存模型\n",
    "    joblib.dump(vote,r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\vote_sub5.model')\n",
    "    #vote = joblib.load(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\0.7835820895522388vote1.model')\n",
    "    y_test_pred = vote.predict(x_test)\n",
    "    pre = pd.DataFrame(y_test_pred,index=None,columns=['Survived'])\n",
    "    pre.to_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\pre5.csv\",index=None)\n",
    "    df = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\test.csv')\n",
    "    dfID = df.PassengerId\n",
    "    sub = pd.concat([dfID,pre],axis=1)\n",
    "    sub.to_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\sub5.csv\", index=None)\n",
    "    print (\"ok\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def sub():\n",
    "    x_train = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_train_feature.csv', header=None).values\n",
    "    y_train = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\train_tag.csv', header=None).values\n",
    "    x_test = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_test_feature.csv', header=None).values\n",
    "    #集合方法\n",
    "    clf1 = svm.SVC(probability=True,random_state=4)\n",
    "    clf2 = RandomForestClassifier(random_state=4)\n",
    "    clf3 = GradientBoostingClassifier(random_state=4)\n",
    "    voting_class = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('dt', clf3)], voting='soft',\n",
    "                                    weights=[1, 1, 1])\n",
    "    vote = voting_class.fit(x_train, y_train)\n",
    "    #保存模型\n",
    "    joblib.dump(vote,r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\vote_sub4.model')\n",
    "    #vote = joblib.load(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\0.7835820895522388vote1.model')\n",
    "    y_test_pred = vote.predict(x_test)\n",
    "    pre = pd.DataFrame(y_test_pred,index=None,columns=['Survived'])\n",
    "    pre.to_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\pre4.csv\",index=None)\n",
    "    df = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\test.csv')\n",
    "    dfID = df.PassengerId\n",
    "    sub = pd.concat([dfID,pre],axis=1)\n",
    "    sub.to_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\sub4.csv\", index=None)\n",
    "    print (\"ok\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def sub():\n",
    "    x_train = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_train_feature.csv', header=None).values\n",
    "    y_train = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\train_tag.csv', header=None).values\n",
    "    x_test = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_test_feature.csv', header=None).values\n",
    "    #集合方法\n",
    "    clf1 = svm.SVC(probability=True,random_state=3)\n",
    "    clf2 = RandomForestClassifier(random_state=3)\n",
    "    clf3 = GradientBoostingClassifier(random_state=3)\n",
    "    voting_class = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('dt', clf3)], voting='soft',\n",
    "                                    weights=[1, 1, 1])\n",
    "    vote = voting_class.fit(x_train, y_train)\n",
    "    #保存模型\n",
    "    joblib.dump(vote,r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\vote_sub3.model')\n",
    "    #vote = joblib.load(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\0.7835820895522388vote1.model')\n",
    "    y_test_pred = vote.predict(x_test)\n",
    "    pre = pd.DataFrame(y_test_pred,index=None,columns=['Survived'])\n",
    "    pre.to_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\pre3.csv\",index=None)\n",
    "    df = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\test.csv')\n",
    "    dfID = df.PassengerId\n",
    "    sub = pd.concat([dfID,pre],axis=1)\n",
    "    sub.to_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\sub3.csv\", index=None)\n",
    "    print (\"ok\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def sub():\n",
    "    x_train = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_train_feature.csv', header=None).values\n",
    "    y_train = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\train_tag.csv', header=None).values\n",
    "    x_test = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_test_feature.csv', header=None).values\n",
    "    #集合方法\n",
    "    clf1 = svm.SVC(probability=True,random_state=2)\n",
    "    clf2 = RandomForestClassifier(random_state=2)\n",
    "    clf3 = GradientBoostingClassifier(random_state=2)\n",
    "    voting_class = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('dt', clf3)], voting='soft',\n",
    "                                    weights=[1, 1, 1])\n",
    "    vote = voting_class.fit(x_train, y_train)\n",
    "    #保存模型\n",
    "    joblib.dump(vote,r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\vote_sub2.model')\n",
    "    #vote = joblib.load(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\0.7835820895522388vote1.model')\n",
    "    y_test_pred = vote.predict(x_test)\n",
    "    pre = pd.DataFrame(y_test_pred,index=None,columns=['Survived'])\n",
    "    pre.to_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\pre2.csv\",index=None)\n",
    "    df = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\test.csv')\n",
    "    dfID = df.PassengerId\n",
    "    sub = pd.concat([dfID,pre],axis=1)\n",
    "    sub.to_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\sub2.csv\", index=None)\n",
    "    print (\"ok\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def sub():\n",
    "    x_train = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_train_feature.csv', header=None).values\n",
    "    y_train = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\train_tag.csv', header=None).values\n",
    "    x_test = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_test_feature.csv', header=None).values\n",
    "    #集合方法\n",
    "    clf1 = svm.SVC(probability=True,random_state=1)\n",
    "    clf2 = RandomForestClassifier(random_state=1)\n",
    "    clf3 = GradientBoostingClassifier(random_state=1)\n",
    "    voting_class = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('dt', clf3)], voting='soft',\n",
    "                                    weights=[1, 1, 1])\n",
    "    vote = voting_class.fit(x_train, y_train)\n",
    "    #保存模型\n",
    "    joblib.dump(vote,r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\vote_sub1.model')\n",
    "    #vote = joblib.load(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\0.7835820895522388vote1.model')\n",
    "    y_test_pred = vote.predict(x_test)\n",
    "    pre = pd.DataFrame(y_test_pred,index=None,columns=['Survived'])\n",
    "    pre.to_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\pre1.csv\",index=None)\n",
    "    df = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\test.csv')\n",
    "    dfID = df.PassengerId\n",
    "    sub = pd.concat([dfID,pre],axis=1)\n",
    "    sub.to_csv(r\"C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\sub1.csv\", index=None)\n",
    "    print (\"ok\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    sub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART FOUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc/test accuracies 0.8494/0.7761\n",
      "SVM train/test accuracies 0.8402/0.7687\n",
      "gbdt/test accuracies 0.8481/0.7836\n",
      "Ensemble Classifier train/test accuracies 0.8481/0.7836\n"
     ]
    }
   ],
   "source": [
    "def fit():\n",
    "    feature = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\cleaned_train_feature.csv',header=None).values\n",
    "    target = pd.read_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\cleaned_data\\\\train_tag.csv',header=None).values\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(feature,target,test_size=0.15,random_state=None)\n",
    "\n",
    "    # 随机森林\n",
    "    rfc = RandomForestClassifier(n_estimators=3,random_state=2)\n",
    "    rfc.fit(x_train,y_train)\n",
    "    y_train_pred = rfc.predict(x_train)\n",
    "    y_test_pred = rfc.predict(x_test)\n",
    "    tree_train = accuracy_score(y_train, y_train_pred)\n",
    "    tree_test = accuracy_score(y_test, y_test_pred)\n",
    "    print('rfc/test accuracies %.4f/%.4f' % (tree_train, tree_test))\n",
    "\n",
    "    # feature_importance = rfc.feature_importances_\n",
    "    # feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    # print(feature_importance)\n",
    "    # cvscores = cross_validation.cross_val_score(rfc, feature, target, cv=5)\n",
    "    # print(cvscores.mean())\n",
    "\n",
    "    # svm\n",
    "    svmMod = svm.SVC(probability=True,random_state=2)\n",
    "    svmMod.fit(x_train, y_train)\n",
    "    y_train_pred = svmMod.predict(x_train)\n",
    "    y_test_pred = svmMod.predict(x_test)\n",
    "    tree_train = accuracy_score(y_train, y_train_pred)\n",
    "    tree_test = accuracy_score(y_test, y_test_pred)\n",
    "    print('SVM train/test accuracies %.4f/%.4f' % (tree_train, tree_test))\n",
    "\n",
    "\n",
    "    # 使用gbdt来分类\n",
    "    gbdt = GradientBoostingClassifier(random_state=2)\n",
    "    gbdt = gbdt.fit(x_train, y_train)\n",
    "    y_train_pred = gbdt.predict(x_train)\n",
    "    y_test_pred = gbdt.predict(x_test)\n",
    "    tree_train = accuracy_score(y_train, y_train_pred)\n",
    "    tree_test = accuracy_score(y_test, y_test_pred)\n",
    "    print('gbdt/test accuracies %.4f/%.4f' % (tree_train, tree_test))\n",
    "\n",
    "    # 集合方法 随机性的模型都会有个random_state来控制随机种子，所以得到一个好模型后记下这个值用来复现模型。\n",
    "    voting_class = VotingClassifier(estimators=[('rfc', rfc), ('gbdt', gbdt),('svm',svmMod)], voting='soft',\n",
    "                                    weights=[1, 1, 1])\n",
    "    vote = voting_class.fit(x_train, y_train)\n",
    "    y_train_pred = vote.predict(x_train)\n",
    "    y_test_pred = vote.predict(x_test)\n",
    "    vote_train = accuracy_score(y_train, y_train_pred)\n",
    "    vote_test = accuracy_score(y_test, y_test_pred)\n",
    "    print('Ensemble Classifier train/test accuracies %.4f/%.4f' % (vote_train, vote_test))\n",
    "    #保存模型 ,compress=3解决了生成一堆文件的问题\n",
    "    joblib.dump(vote,'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\' + str(vote_test) + 'vote1.model',compress=3)\n",
    "    #vote = joblib.load('vote.model')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART FIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "7\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def ensemble():\n",
    "    array1 = pd.read_csv(open('C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\sub1.csv'), header=None).values\n",
    "    array2 = pd.read_csv(open('C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\sub2.csv'), header=None).values\n",
    "    array3 = pd.read_csv(open('C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\sub3.csv'), header=None).values\n",
    "    array4 = pd.read_csv(open('C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\sub4.csv'), header=None).values\n",
    "    array5 = pd.read_csv(open('C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\sub5.csv'),header=None).values\n",
    "    array6 = pd.read_csv(open('C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\sub6.csv'), header=None).values\n",
    "    array7 = pd.read_csv(open('C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\sub7.csv'), header=None).values\n",
    "    newarray = pd.read_csv(open('C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\sub1.csv'), header=None).values\n",
    "\n",
    "\n",
    "    for i in range(1,len(array1)):\n",
    "        count = 0\n",
    "        if (array1[i][1] == str(1)): count = count + 1\n",
    "        if (array2[i][1] == str(1)): count = count + 1\n",
    "        if (array3[i][1] == str(1)): count = count + 1\n",
    "        if (array4[i][1] == str(1)): count = count + 1\n",
    "        if (array5[i][1] == str(1)): count = count + 1\n",
    "        if (array6[i][1] == str(1)): count = count + 1\n",
    "        if (array7[i][1] == str(1)): count = count + 1\n",
    "\n",
    "        print (count)\n",
    "        if (count > 3): newarray[i][1] = 1 #相当于在投票，票数>3票就认为获救。\n",
    "        else: newarray[i][1] = 0  #第i行第1列。\n",
    "    df = pd.DataFrame(newarray,index=None)\n",
    "    df.to_csv(r'C:\\\\Users\\\\13121\\\\Desktop\\\\my_notebook\\\\titanic\\\\奇奇怪怪\\\\finalsub.csv',index=None,header=None)\n",
    "\n",
    "\n",
    "    # print array2[0],array2[1],array2[1][0],type(array2[1][1])\n",
    "    # ['PassengerId' 'Survived'] ['892' '0'] 这个array2[1][1]读出来是str格式，我在上边用int比一个都没比出来，要转下型\n",
    "\n",
    "\n",
    "class Main():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
